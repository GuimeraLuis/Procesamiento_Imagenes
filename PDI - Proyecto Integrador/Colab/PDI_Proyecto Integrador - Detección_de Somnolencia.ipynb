{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eqd-P29jZpIT"
      },
      "outputs": [],
      "source": [
        "#Instalamos librerias necesarias\n",
        "!pip install opencv-python mediapipe gradio -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tczx1Ik_7h33"
      },
      "outputs": [],
      "source": [
        "# Importamos paquetes necesarios\n",
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "from scipy.spatial import distance as dist\n",
        "import gradio as gr\n",
        "import tempfile\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "Co88vLTs8TVy",
        "outputId": "4404a976-459c-4d7d-bb6c-b951ef934df7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://e214f9e8dad51de511.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e214f9e8dad51de511.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> None\n",
            "Killing tunnel 127.0.0.1:7861 <> https://e214f9e8dad51de511.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "def eye_aspect_ratio(ojo):\n",
        "    # Calculo de la distancia euclidiana entre los dos conjuntos de coordenadas verticales\n",
        "    A = dist.euclidean(ojo[1], ojo[5])\n",
        "    B = dist.euclidean(ojo[2], ojo[4])\n",
        "    # Calculo de la distancia euclidiana entre las coordenadas horizontales\n",
        "    C = dist.euclidean(ojo[0], ojo[3])\n",
        "    # Calculo de la relación de aspecto del ojo\n",
        "    ear = (A + B) / (2.0 * C)\n",
        "\n",
        "    return ear\n",
        "\n",
        "# Constantes\n",
        "EAR_UMBRAL = 0.3\n",
        "EAR_FRAMES = 5\n",
        "\n",
        "# Inicializacion de contador de cuadros y alarma\n",
        "CONTADOR = 0\n",
        "ALARMA = False\n",
        "\n",
        "# Inicializacion de MediaPipe Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
        "\n",
        "# Índices para los puntos de referencia de los ojos (ajustar si es necesario)\n",
        "INDICE_OJO_IZQ = [362, 385, 387, 263, 373, 380]\n",
        "INDICE_OJO_DER = [33, 160, 158, 133, 153, 144]\n",
        "\n",
        "\n",
        "def procesamiento_video(video_path):\n",
        "    global CONTADOR, ALARMA, INDICE_OJO_IZQ, INDICE_OJO_DER\n",
        "    CONTADOR = 0\n",
        "    ALARMA = False\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error al abrir el archivo\")\n",
        "        return\n",
        "\n",
        "    # propiedades del video original\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # para construcción de video de salida\n",
        "    temp_output_file = tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False)\n",
        "    temp_output_path = temp_output_file.name\n",
        "    temp_output_file.close()\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(temp_output_path, fourcc, fps, (width, height))\n",
        "\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Conversion a RGB\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Proceso con MediaPipe Face Mesh\n",
        "        resultado = face_mesh.process(frame_rgb)\n",
        "\n",
        "        if resultado.multi_face_landmarks:\n",
        "            for face_landmarks in resultado.multi_face_landmarks:\n",
        "                # Dibujo de malla facial\n",
        "                mp_drawing.draw_landmarks(\n",
        "                    image=frame,\n",
        "                    landmark_list=face_landmarks,\n",
        "                    connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
        "                    landmark_drawing_spec=None,\n",
        "                    connection_drawing_spec=drawing_spec)\n",
        "\n",
        "                # Extraccion de ojos\n",
        "                landmarks = np.array([(lm.x * width, lm.y * height) for lm in face_landmarks.landmark])\n",
        "                landmarks_ojo_izq = landmarks[INDICE_OJO_IZQ]\n",
        "                landmarks_ojo_der = landmarks[INDICE_OJO_DER]\n",
        "\n",
        "                # Calculo de ear de ambos ojos\n",
        "                izq_ear = eye_aspect_ratio(landmarks_ojo_izq)\n",
        "                der_ear = eye_aspect_ratio(landmarks_ojo_der)\n",
        "\n",
        "                # Average de ear\n",
        "                ear = (izq_ear + der_ear) / 2.0\n",
        "\n",
        "                # Chequeo de UMBRAL\n",
        "                if ear < EAR_UMBRAL:\n",
        "                    CONTADOR += 1\n",
        "                    # si ojos permanecen cerrados duarnte mayor tiempo que los indicados\n",
        "                    # se muestra alarma\n",
        "                    if CONTADOR >= EAR_FRAMES:\n",
        "                        # si alarma esta desactivada, se cambia estado\n",
        "                        if not ALARMA:\n",
        "                            ALARMA = True\n",
        "\n",
        "                        # Alarma en el frame\n",
        "                        cv2.putText(frame, \"ALERTA DE SOMNOLENCIA!\", (10, 30),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "\n",
        "                # reseteo de CONTADOR cambio estado de alarma\n",
        "                else:\n",
        "                    CONTADOR = 0\n",
        "                    ALARMA = False\n",
        "\n",
        "                # dibujo de ear en el frame\n",
        "                cv2.putText(frame, \"EAR: {:.2f}\".format(ear), (300, 30),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
        "\n",
        "        out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    return temp_output_path\n",
        "\n",
        "# creacion de interfaz con Gradio\n",
        "iface = gr.Interface(\n",
        "    fn=procesamiento_video,\n",
        "    inputs=gr.Video(label=\"Subir Video\"),\n",
        "    outputs=gr.Video(label=\"Video Procesado\"),\n",
        "    title=\"Detección de Somnolencia usando MediaPipe\",\n",
        "    description=\"Cargar video para detectar somnolencia en base a calculo de apertura de ojos.\"\n",
        ")\n",
        "\n",
        "iface.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}